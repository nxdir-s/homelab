---
ollama:
  # -- Automatically install Ollama Helm chart from https://otwld.github.io/ollama-helm/. Use [Helm Values](https://github.com/otwld/ollama-helm/#helm-values) to configure
  enabled: false
  # -- If enabling embedded Ollama, update fullnameOverride to your desired Ollama name value, or else it will use the default ollama.name value from the Ollama chart
  fullnameOverride: "ollama"
  tolerations:
    - key: "gpu"
      operator: "Equal"
      value: "true"
      effect: "NoSchedule"
  # -- Example Ollama configuration with nvidia GPU enabled, automatically downloading a model, and deploying a PVC for model persistence
  ollama:
    gpu:
      enabled: false
    models:
      pull:
        - llama3.2
      run:
        - llama3.2
  resources:
    requests:
      memory: 4Gi
      cpu: 2000m
  persistentVolume:
    enabled: true
    size: 50Gi

pipelines:
  enabled: false

# -- A list of Ollama API endpoints. These can be added in lieu of automatically installing the Ollama Helm chart, or in addition to it.
ollamaUrls: ["http://192.168.1.221:11434"]

# -- Disables taking Ollama Urls from `ollamaUrls`  list
ollamaUrlsFromExtraEnv: false

annotations: {}
podAnnotations: {}
podLabels: {}
replicaCount: 1
# -- Open WebUI image tags can be found here: https://github.com/open-webui/open-webui
image:
  repository: ghcr.io/open-webui/open-webui
  tag: ""
  pullPolicy: "IfNotPresent"

# -- Open WebUI container command (overrides default entrypoint)
command: []
# -- Open WebUI container arguments (overrides default)
args: []

serviceAccount:
  enable: true
  name: ""
  annotations: {}
  automountServiceAccountToken: false

resources: {}

persistence:
  enabled: true
  size: 2Gi
  # -- Use existingClaim if you want to re-use an existing Open WebUI PVC instead of creating a new one
  existingClaim: ""
  # -- Subdirectory of Open WebUI PVC to mount. Useful if root directory is not empty.
  subPath: ""
  # -- If using multiple replicas, you must update accessModes to ReadWriteMany
  accessModes:
    - ReadWriteOnce
  storageClass: "longhorn"
  selector: {}
  annotations: {}
  # -- Sets the storage provider, availables values are `local`, `s3`, `gcs` or `azure`
  provider: local
  s3:
    # -- Sets the access key ID for S3 storage
    # @section -- Amazon S3 Storage configuration
    accessKey: ""
    # -- Sets the secret access key for S3 storage (ignored if secretKeyExistingSecret is set)
    # @section -- Amazon S3 Storage configuration
    secretKey: ""
    # -- Set the secret access key for S3 storage from existing k8s secret
    # @section -- Amazon S3 Storage configuration
    accessKeyExistingSecret: ""
    # -- Set the secret access key for S3 storage from existing k8s secret key
    # @section -- Amazon S3 Storage configuration
    accessKeyExistingAccessKey: ""
    # -- Set the secret key for S3 storage from existing k8s secret
    # @section -- Amazon S3 Storage configuration
    secretKeyExistingSecret: ""
    # -- Set the secret key for S3 storage from existing k8s secret key
    # @section -- Amazon S3 Storage configuration
    secretKeyExistingSecretKey: ""
    # -- Sets the endpoint url for S3 storage
    # @section -- Amazon S3 Storage configuration
    endpointUrl: ""
    # -- Sets the region name for S3 storage
    # @section -- Amazon S3 Storage configuration
    region: ""
    # -- Sets the bucket name for S3 storage
    # @section -- Amazon S3 Storage configuration
    bucket: ""
    # -- Sets the key prefix for a S3 object
    # @section -- Amazon S3 Storage configuration
    keyPrefix: ""

# -- Node labels for pod assignment.
# nodeSelector:
#   gpu: "true"

# tolerations:
#   - key: "gpu"
#     operator: "Equal"
#     value: "true"
#     effect: "NoSchedule"

# -- Service values to expose Open WebUI pods to cluster
service:
  type: ClusterIP
  annotations: {}
  port: 80
  containerPort: 8080
  labels: {}

# -- Env vars added to the Open WebUI deployment. Most up-to-date environment variables can be found here: https://docs.openwebui.com/getting-started/env-configuration/
extraEnvVars:
  # -- Default API key value for Pipelines. Should be updated in a production deployment, or be changed to the required API key if not using Pipelines
  - name: OPENAI_API_KEY
    value: "0p3n-w3bu!"
  # valueFrom:
  #   secretKeyRef:
  #     name: pipelines-api-key
  #     key: api-key
  # - name: OPENAI_API_KEY
  #   valueFrom:
  #     secretKeyRef:
  #       name: openai-api-key
  #       key: api-key
  # - name: OLLAMA_DEBUG
  #   value: "1"
# -- Env vars added to the Open WebUI deployment, common across environments. Most up-to-date environment variables can be found here: https://docs.openwebui.com/getting-started/env-configuration/ (caution: environment variables defined in both `extraEnvVars` and `commonEnvVars` will result in a conflict. Avoid duplicates)
# commonEnvVars:
#   - name: CUDA_VISIBLE_DEVICES
#     value: "0"
